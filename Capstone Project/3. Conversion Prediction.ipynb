{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "higher-commerce",
   "metadata": {},
   "source": [
    "# __3. 3. Conversion Prediction__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hispanic-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adopted-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickles\n",
    "df_train = pd.read_pickle(\"df_train.pkl\")\n",
    "df_test = pd.read_pickle(\"df_test.pkl\")\n",
    "df_valid = pd.read_pickle(\"df_valid.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adjusted-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data X/y \n",
    "X_train = df_train.drop('y',axis=1).values\n",
    "y_train = df_train['y'].values\n",
    "\n",
    "# Test data X/y \n",
    "X_test = df_test.drop('y',axis=1).values\n",
    "y_test = df_test['y'].values\n",
    "\n",
    "# Validation data X/y \n",
    "X_valid = df_valid.drop('y',axis=1).values\n",
    "y_valid = df_valid['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-ethnic",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 1. Logistic Regression\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-microphone",
   "metadata": {},
   "source": [
    "#### 1.1 Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "realistic-nebraska",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy logistic regression: 0.90%\n"
     ]
    }
   ],
   "source": [
    "# Create Pipeline\n",
    "logreg_base = Pipeline ([\n",
    "        ((\"enc\", OneHotEncoder(handle_unknown = 'ignore'))),\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"logreg\", LogisticRegression(multi_class='ovr', solver='liblinear'))\n",
    "])\n",
    "\n",
    "# Fit Pipeline\n",
    "logreg_base.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy on test set\n",
    "accuracy_logreg = logreg_base.score(X_valid, y_valid)\n",
    "print('accuracy logistic regression: {:.2f}%'.format(accuracy_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-reduction",
   "metadata": {},
   "source": [
    "#### 1.2 Tuned model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ceramic-sullivan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('enc', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)), ('scaler', StandardScaler(copy=True, with_mean=False, with_std=True)), ('logreg', LogisticRegression(C=1.0, class_weight=None, ...ty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'logreg__C': array([1.00000e-05, 1.29155e-04, 1.66810e-03, 2.15443e-02, 2.78256e-01,\n",
       "       3.59381e+00, 4.64159e+01, 5.99484e+02, 7.74264e+03, 1.00000e+05])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Pipeline\n",
    "logreg_cv = Pipeline ([\n",
    "        ((\"enc\", OneHotEncoder(handle_unknown = 'ignore'))),\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"logreg\", LogisticRegression(multi_class='ovr', solver='liblinear'))\n",
    "])\n",
    "\n",
    "# Create cross-validation\n",
    "grid = {'logreg__C': np.logspace(-5, 5, num=10)} # Tune C parameter\n",
    "grid_cv = GridSearchCV(logreg_cv, grid, cv=5, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "# Fit model\n",
    "grid_cv.fit(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "innovative-victim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>param_logreg__C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.895120</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.916181</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.0016681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.891721</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.898185</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000129155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.889779</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.917911</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.0215443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.889172</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.918002</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.278256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.888687</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>0.917911</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>3.59381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.888687</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.917911</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>46.4159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.888687</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.917911</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>599.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.888565</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.917911</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>7742.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.888565</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.917911</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.886137</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.886775</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>1e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score  mean_train_score  std_train_score  \\\n",
       "2         0.895120        0.003907          0.916181         0.001088   \n",
       "1         0.891721        0.002089          0.898185         0.000463   \n",
       "3         0.889779        0.004543          0.917911         0.000785   \n",
       "4         0.889172        0.005525          0.918002         0.000744   \n",
       "5         0.888687        0.005057          0.917911         0.000590   \n",
       "6         0.888687        0.005213          0.917911         0.000656   \n",
       "7         0.888687        0.005213          0.917911         0.000656   \n",
       "8         0.888565        0.005323          0.917911         0.000656   \n",
       "9         0.888565        0.005323          0.917911         0.000656   \n",
       "0         0.886137        0.000449          0.886775         0.000116   \n",
       "\n",
       "  param_logreg__C  \n",
       "2       0.0016681  \n",
       "1     0.000129155  \n",
       "3       0.0215443  \n",
       "4        0.278256  \n",
       "5         3.59381  \n",
       "6         46.4159  \n",
       "7         599.484  \n",
       "8         7742.64  \n",
       "9          100000  \n",
       "0           1e-05  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_cv.cv_results_)\n",
    "\n",
    "#print the most relevant columns\n",
    "cols = ['mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score', 'param_logreg__C']\n",
    "tuned_logreg=cv_results[cols].sort_values('mean_test_score', ascending=False)\n",
    "tuned_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-ecuador",
   "metadata": {},
   "source": [
    "Changing the C parameter doesn't seem to improve the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unlikely-error",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('enc', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)), ('scaler', StandardScaler(copy=True, with_mean=False, with_std=True)), ('logreg', LogisticRegression(C=0.0016681005372000592, c...ty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the best peforimng C-parameter\n",
    "Tuned_C = tuned_logreg['param_logreg__C'].iloc[0]\n",
    "\n",
    "tuned_logreg = Pipeline ([\n",
    "        ((\"enc\", OneHotEncoder(handle_unknown = 'ignore'))),\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"logreg\", LogisticRegression(multi_class='ovr', solver='liblinear', C=Tuned_C))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "tuned_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "prospective-generic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy tuned logistic regression: 0.90%\n"
     ]
    }
   ],
   "source": [
    "tuned_accuracy_logreg = tuned_logreg.score(X_test, y_test)\n",
    "print('Accuracy tuned logistic regression: {:.2f}%'.format(tuned_accuracy_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "clean-large",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-863bd589ed50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Calculate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_valid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuned_logreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlogreg_confusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate predictions\n",
    "y_valid_pred = tuned_logreg.predict(X_valid)\n",
    "\n",
    "logreg_confusion_matrix = confusion_matrix(y_valid, y_valid_pred)\n",
    "\n",
    "logreg_confusion_matrix # cannot import confusionmatrixdisplay from scikit - not sure why. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-granny",
   "metadata": {},
   "source": [
    "A relative high number of false postivie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "former-reply",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tuned_logreg.joblib']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# Save estimator\n",
    "joblib.dump(tuned_logreg, \"tuned_logreg.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-russian",
   "metadata": {},
   "source": [
    "## 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-moderator",
   "metadata": {},
   "source": [
    "#### 2.1 Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "blocked-reflection",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samerre/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy random forest: 0.89%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create Pipeline\n",
    "ranfor = Pipeline ([\n",
    "        ((\"enc\", OneHotEncoder(handle_unknown = 'ignore'))),\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"ranfor\", RandomForestClassifier(criterion='gini',random_state=0))\n",
    "])\n",
    "\n",
    "# Fit Pipeline\n",
    "ranfor.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy on test set\n",
    "accuracy_ranfor = ranfor.score(X_valid, y_valid)\n",
    "print('accuracy random forest: {:.2f}%'.format(accuracy_ranfor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-warehouse",
   "metadata": {},
   "source": [
    "#### 2.2 Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adaptive-packing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('enc', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)), ('scaler', StandardScaler(copy=True, with_mean=False, with_std=True)), ('ranfor', RandomForestClassifier(bootstrap=True, class_...ors='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'ranfor__n_estimators': [1, 5, 10, 20, 50, 100, 200], 'ranfor__max_depth': [1, 3, 5, 10, 50, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Pipeline\n",
    "ranfor_tuned = Pipeline ([\n",
    "        ((\"enc\", OneHotEncoder(handle_unknown = 'ignore'))),\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"ranfor\", RandomForestClassifier(criterion='gini',random_state=0))\n",
    "])\n",
    "\n",
    "grid = {\n",
    "    \"ranfor__n_estimators\": [1,5,10,20,50,100,200],\n",
    "    \"ranfor__max_depth\": [1,3,5,10,50,None]\n",
    "}\n",
    "\n",
    "dtcv = GridSearchCV(ranfor_tuned,grid,cv=5,return_train_score=True)\n",
    "\n",
    "dtcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "pressing-breakfast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ranfor__max_depth': 10, 'ranfor__n_estimators': 50}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "headed-gibson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010197474910975"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "julian-branch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('enc', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)), ('scaler', StandardScaler(copy=True, with_mean=False, with_std=True)), ('ranfor', RandomForestClassifier(bootstrap=True, class_...imators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the best peforimng C-parameter\n",
    "best_max_depth = dtcv.best_params_['ranfor__max_depth']\n",
    "best_n_estimators = dtcv.best_params_['ranfor__n_estimators']\n",
    "\n",
    "ranfor_best = Pipeline ([\n",
    "        ((\"enc\", OneHotEncoder(handle_unknown = 'ignore'))),\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"ranfor\", RandomForestClassifier(criterion='gini',random_state=0, n_estimators = best_n_estimators, max_depth = best_max_depth))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "ranfor_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcv_test_predictions = dtcv.predict(X_test)\n",
    "dtcv_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-albert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "computational-region",
   "metadata": {},
   "source": [
    "## 3. XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-detection",
   "metadata": {},
   "source": [
    "#### 3.1 Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joint-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "opposed-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgboost = xgboost.XGBClassifier(learning_rate = 0.1,\n",
    "                                    max_depth =20,\n",
    "                                    n_estimators=5000,\n",
    "                                    subsample=0.5,\n",
    "                                    colsample_bytree=0.5,\n",
    "                                    eval_metric=\"auc\",\n",
    "                                    verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "electronic-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode dasets\n",
    "df_train_enc = pd.get_dummies(df_train)\n",
    "df_valid_enc = pd.get_dummies(df_valid)\n",
    "\n",
    "# Train data X/y \n",
    "X_train_enc = df_train_enc.drop('y',axis=1).values\n",
    "y_train_enc = df_train_enc['y'].values\n",
    "\n",
    "# Test data X/y \n",
    "X_valid_enc = df_valid_enc.drop('y',axis=1).values\n",
    "y_valid_enc = df_valid_enc['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "improved-copying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.77343\n",
      "[1]\tvalidation_0-auc:0.77751\n",
      "[2]\tvalidation_0-auc:0.78344\n",
      "[3]\tvalidation_0-auc:0.78631\n",
      "[4]\tvalidation_0-auc:0.78873\n",
      "[5]\tvalidation_0-auc:0.79139\n",
      "[6]\tvalidation_0-auc:0.79136\n",
      "[7]\tvalidation_0-auc:0.79268\n",
      "[8]\tvalidation_0-auc:0.79189\n",
      "[9]\tvalidation_0-auc:0.78957\n",
      "[10]\tvalidation_0-auc:0.78980\n",
      "[11]\tvalidation_0-auc:0.79044\n",
      "[12]\tvalidation_0-auc:0.79049\n",
      "[13]\tvalidation_0-auc:0.79198\n",
      "[14]\tvalidation_0-auc:0.79149\n",
      "[15]\tvalidation_0-auc:0.79003\n",
      "[16]\tvalidation_0-auc:0.79107\n",
      "[17]\tvalidation_0-auc:0.78975\n",
      "[18]\tvalidation_0-auc:0.78970\n",
      "[19]\tvalidation_0-auc:0.78962\n",
      "[20]\tvalidation_0-auc:0.79275\n",
      "[21]\tvalidation_0-auc:0.79329\n",
      "[22]\tvalidation_0-auc:0.79284\n",
      "[23]\tvalidation_0-auc:0.79246\n",
      "[24]\tvalidation_0-auc:0.79263\n",
      "[25]\tvalidation_0-auc:0.79269\n",
      "[26]\tvalidation_0-auc:0.79260\n",
      "[27]\tvalidation_0-auc:0.79145\n",
      "[28]\tvalidation_0-auc:0.79123\n",
      "[29]\tvalidation_0-auc:0.79184\n",
      "[30]\tvalidation_0-auc:0.79034\n",
      "[31]\tvalidation_0-auc:0.79085\n",
      "[32]\tvalidation_0-auc:0.79067\n",
      "[33]\tvalidation_0-auc:0.78952\n",
      "[34]\tvalidation_0-auc:0.79006\n",
      "[35]\tvalidation_0-auc:0.78895\n",
      "[36]\tvalidation_0-auc:0.78897\n",
      "[37]\tvalidation_0-auc:0.78840\n",
      "[38]\tvalidation_0-auc:0.78688\n",
      "[39]\tvalidation_0-auc:0.78500\n",
      "[40]\tvalidation_0-auc:0.78676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.5, eval_metric='auc',\n",
       "       gamma=0, gpu_id=-1, importance_type='gain',\n",
       "       interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=20, min_child_weight=1, missing=nan,\n",
       "       monotone_constraints='()', n_estimators=5000, n_jobs=8,\n",
       "       num_parallel_tree=1, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.5,\n",
       "       tree_method='exact', use_label_encoder=True, validate_parameters=1,\n",
       "       verbosity=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(X_valid_enc, y_valid_enc)]\n",
    "\n",
    "model_xgboost.fit(X_train_enc,\n",
    "                 y_train_enc,\n",
    "                 early_stopping_rounds=20,\n",
    "                 eval_set=eval_set,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hungarian-counter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train set: 0.88%\n",
      "accuracy validation set: 0.79%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_train_pred = model_xgboost.predict_proba(X_train_enc)[:,1]\n",
    "y_valid_pred = model_xgboost.predict_proba(X_valid_enc)[:,1]\n",
    "\n",
    "print('accuracy train set: {:.2f}%'.format(roc_auc_score(y_train_enc, y_train_pred)))\n",
    "print('accuracy validation set: {:.2f}%'.format(roc_auc_score(y_valid_enc, y_valid_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-worth",
   "metadata": {},
   "source": [
    "#### 3.2 Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "clean-management",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=1000 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/samerre/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=1000, score=0.9039815489196407, total=   4.9s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=1000 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=1000, score=0.9022702440208814, total=   6.6s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=1000 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   11.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=1000, score=0.899963578972927, total=   6.1s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=2000 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   17.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=2000, score=0.9009468317552805, total=   9.6s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=2000, score=0.9021488405973048, total=   9.0s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=2000, score=0.9002063858200802, total=   9.8s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=3000, score=0.9003398883224083, total=  13.2s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=3000, score=0.9022702440208814, total=  17.8s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=3000, score=0.9006919995143863, total=  20.1s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=1000, score=0.9010682204418549, total=   8.3s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=1000, score=0.9020274371737284, total=   8.1s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=1000, score=0.899963578972927, total=   8.0s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=2000, score=0.898154891964069, total=  16.4s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=2000, score=0.9022702440208814, total=  16.2s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=2000, score=0.9016632269029987, total=  16.0s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=3000, score=0.8975479485311969, total=  17.4s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=3000, score=0.9011776132086925, total=  21.7s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=3000, score=0.9003277892436566, total=  20.8s\n",
      "[CV] learning_rate=0.02, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=4, n_estimators=1000, score=0.899368778829813, total=   9.5s\n",
      "[CV] learning_rate=0.02, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=4, n_estimators=1000, score=0.9020274371737284, total=   9.7s\n",
      "[CV] learning_rate=0.02, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=4, n_estimators=1000, score=0.9008134029379629, total=  11.4s\n",
      "[CV] learning_rate=0.02, max_depth=4, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=4, n_estimators=2000, score=0.896698227725176, total=  22.2s\n",
      "[CV] learning_rate=0.02, max_depth=4, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=4, n_estimators=2000, score=0.9010562097851159, total=  20.5s\n",
      "[CV] learning_rate=0.02, max_depth=4, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=4, n_estimators=2000, score=0.9006919995143863, total=  20.2s\n",
      "[CV] learning_rate=0.02, max_depth=4, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=4, n_estimators=3000, score=0.8948773974265598, total=  28.7s\n",
      "[CV] learning_rate=0.02, max_depth=4, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=4, n_estimators=3000, score=0.9003277892436566, total=  26.7s\n",
      "[CV] learning_rate=0.02, max_depth=4, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=4, n_estimators=3000, score=0.899963578972927, total=  25.3s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=1000, score=0.896698227725176, total=  12.6s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=1000, score=0.9006919995143863, total=  13.9s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=1000, score=0.8994779652786209, total=  10.8s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=2000, score=0.8947560087399854, total=  23.0s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=2000, score=0.8993565618550443, total=  28.0s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=2000, score=0.8985067378900085, total=  25.3s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=3000, score=0.8941490653071134, total=  33.7s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=3000, score=0.898628141313585, total=  32.4s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=3000, score=0.8975355105013961, total=  33.1s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=1000, score=0.9011896091284293, total=   6.5s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=1000, score=0.9016632269029987, total=   6.2s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=1000, score=0.9008134029379629, total=   7.1s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=2000, score=0.8985190580237922, total=  10.3s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=2000, score=0.9012990166322691, total=  10.6s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=2000, score=0.9004491926672332, total=  12.8s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=3000, score=0.8982762806506434, total=  18.7s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=3000, score=0.9003277892436566, total=  27.9s\n",
      "[CV] learning_rate=0.05, max_depth=2, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=2, n_estimators=3000, score=0.8994779652786209, total=  25.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=3, n_estimators=1000, score=0.8985190580237922, total=   8.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=3, n_estimators=1000, score=0.9012990166322691, total=   8.0s\n",
      "[CV] learning_rate=0.05, max_depth=3, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=3, n_estimators=1000, score=0.9002063858200802, total=   7.1s\n",
      "[CV] learning_rate=0.05, max_depth=3, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=3, n_estimators=2000, score=0.8954843408594318, total=  14.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=3, n_estimators=2000, score=0.8985067378900085, total=  16.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=3, n_estimators=2000, score=0.898628141313585, total=  21.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=3, n_estimators=3000, score=0.8935421218742413, total=  18.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=3, n_estimators=3000, score=0.8980211241957023, total=  20.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=3, n_estimators=3000, score=0.898385334466432, total=  22.2s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=1000, score=0.8941490653071134, total=  10.4s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=1000, score=0.898628141313585, total=  12.9s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=1000, score=0.8987495447371616, total=   8.7s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=2000, score=0.8928137897547949, total=  16.7s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=2000, score=0.8975355105013961, total=  21.6s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=2000, score=0.8987495447371616, total=  21.4s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=3000, score=0.8914785142024764, total=  33.1s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=3000, score=0.8974141070778195, total=  32.6s\n",
      "[CV] learning_rate=0.05, max_depth=4, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=4, n_estimators=3000, score=0.8970498968070899, total=  32.1s\n",
      "[CV] learning_rate=0.05, max_depth=5, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=5, n_estimators=1000, score=0.8924496236950716, total=  10.3s\n",
      "[CV] learning_rate=0.05, max_depth=5, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=5, n_estimators=1000, score=0.8991137550078913, total=   9.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, n_estimators=1000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=5, n_estimators=1000, score=0.8982639310428554, total=  10.7s\n",
      "[CV] learning_rate=0.05, max_depth=5, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=5, n_estimators=2000, score=0.890507404709881, total=  28.6s\n",
      "[CV] learning_rate=0.05, max_depth=5, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=5, n_estimators=2000, score=0.8959572659949011, total=  23.7s\n",
      "[CV] learning_rate=0.05, max_depth=5, n_estimators=2000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=5, n_estimators=2000, score=0.894621828335559, total=  31.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=5, n_estimators=3000, score=0.888443797038116, total=  49.2s\n",
      "[CV] learning_rate=0.05, max_depth=5, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=5, n_estimators=3000, score=0.8940148112176763, total=  43.7s\n",
      "[CV] learning_rate=0.05, max_depth=5, n_estimators=3000 ..............\n",
      "[CV]  learning_rate=0.05, max_depth=5, n_estimators=3000, score=0.8928007769819108, total=  39.4s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=1000, score=0.8976693372177713, total=   5.6s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=1000, score=0.899963578972927, total=   5.7s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=1000, score=0.9010562097851159, total=   5.9s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=2000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=2000, score=0.8959698956057296, total=  16.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=2000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=2000, score=0.8982639310428554, total=  16.6s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=2000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=2000, score=0.8991137550078913, total=  15.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=3000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=3000, score=0.8943918426802622, total=  13.5s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=3000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=3000, score=0.8970498968070899, total=  13.7s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=3000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=3000, score=0.898628141313585, total=  16.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=1000, score=0.8959698956057296, total=   7.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=1000, score=0.898385334466432, total=   8.2s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=1000, score=0.8985067378900085, total=  14.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=2000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=2000, score=0.8931779558145181, total=  18.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=2000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=2000, score=0.8976569139249727, total=  16.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=2000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=2000, score=0.8974141070778195, total=  18.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=3000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=3000, score=0.8897790725904345, total=  24.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=3000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=3000, score=0.8974141070778195, total=  23.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=3000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=3000, score=0.8947432317591356, total=  32.5s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=1000, score=0.8924496236950716, total=  16.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=1000, score=0.8966856865363603, total=  11.5s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=1000, score=0.8959572659949011, total=  12.8s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=2000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=2000, score=0.8894149065307113, total=  16.4s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=2000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=2000, score=0.8958358625713245, total=  23.6s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=2000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=2000, score=0.8931649872526405, total=  27.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=3000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=3000, score=0.8873512988589464, total=  25.2s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=3000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=3000, score=0.8935291975233701, total=  31.1s\n",
      "[CV] learning_rate=0.1, max_depth=4, n_estimators=3000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=4, n_estimators=3000, score=0.8914653393225689, total=  32.2s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=1000, score=0.891964068948774, total=  13.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=1000, score=0.8959572659949011, total=  11.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=1000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=1000, score=0.8953502488770183, total=  14.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=2000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=2000, score=0.8861374119932023, total=  32.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=2000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=2000, score=0.8941362146412529, total=  30.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=2000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=2000, score=0.888794464003885, total=  28.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=3000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=3000, score=0.8852876911871813, total=  45.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=3000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=3000, score=0.8885516571567318, total=  47.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=3000 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=3000, score=0.8880660434624257, total=  40.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed: 34.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.5, eval_metric='auc',\n",
       "       gamma=0, gpu_id=-1, importance_type='gain',\n",
       "       interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=20, min_child...=0.5,\n",
       "       tree_method='exact', use_label_encoder=True, validate_parameters=1,\n",
       "       verbosity=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'learning_rate': [0.02, 0.05, 0.1], 'max_depth': [2, 3, 4, 5], 'n_estimators': [1000, 2000, 3000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {\n",
    "    \"learning_rate\": [0.02, 0.05, 0.1],\n",
    "    \"max_depth\": [2, 3, 4, 5],\n",
    "    \"n_estimators\": [1000, 2000, 3000]\n",
    "}\n",
    "\n",
    "model_xgboost_tuned = GridSearchCV(model_xgboost, grid, cv=3, return_train_score=True, verbose=4)\n",
    "\n",
    "model_xgboost_tuned.fit(X_train_enc, y_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-brazilian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "***\n",
    "\n",
    "## 2.1 K-Means\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
